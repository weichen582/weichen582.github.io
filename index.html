<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- DELETE THIS SCRIPT if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Chen Wei</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images_new/JHU_icon.jpg">
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chen Wei</name>
              </p>
              <p>
                I am a Computer Science Ph.D. student at Johns Hopkins University,
                where I am fortunate to be advised by  <a href="https://en.wikipedia.org/wiki/Bloomberg_Distinguished_Professorships">Bloomberg Distinguished Professor</a>
               <a href="https://cs.jhu.edu/~ayuille/">Alan L. Yuille</a>.
              </p>
              <p>
                I received my B.S. in Computer Science from Peking University. I spent great time at Google Brain, FAIR @ Meta, Google Cloud, and Noah's Ark Lab.
              </p>
              <p>
                My research lies at the intersection of computer vision and machine learning, with a focus on reliable and scalable representation learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:weichen3012@gmail.com">weichen3012 [at] gmail [dot] com</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=LHQGpBUAAAAJ">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images_new/chen_wei.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images_new/chen_wei.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
              [07/16/2023] DiffMAE and SMAUG accepted to ICCV 2023</a>.
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
              [04/23/2023] Hiera accepted to ICML 2023 as oral presentation</a>.
            </td>
          </tr>


          <tr>
            <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
              [04/06/2023] Excited to release our new work on reformulating <a href="https://arxiv.org/abs/2304.03283">Diffusion Models as Masked Autoencoders</a>.
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
              [10/19/2022] Proud to be an <a href="https://eccv2022.ecva.net/program/outstanding-reviewers/">ECCV 2022 outstanding reviewer</a>.
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
              [09/07/2022] Passed my Graduate Board Oral exam and now a PhD candidate :) 
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          <tr onmouseout="diffmae_stop()" onmouseover="diffmae_start()" bgcolor="#ffffd0">
            <td style="padding:40px;padding-top:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='diffmae_image'><img style="width: 120%; height: auto;" src='diffmae/interpolation/2.png'></div>
                <img style="width: 120%; height: auto;" src='diffmae/interpolation/input.png'>
              </div>
              <script type="text/javascript">
                function diffmae_start() {
                  document.getElementById('diffmae_image').style.opacity = "1";
                }

                function diffmae_stop() {
                  document.getElementById('diffmae_image').style.opacity = "0";
                }
                diffmae_stop()
              </script>
            </td>

            <td style="padding:40px;padding-top:70px;width:70%;vertical-align:top">
              <a href="https://arxiv.org/abs/2304.03283">
                <papertitle> Diffusion Models as Masked Autoencoders </papertitle>
              </a>
              <br>
              <strong>Chen Wei</strong>,
              <a href="https://karttikeya.github.io/">Karttikeya Mangalam</a>,
              <a href="http://www.cs.cmu.edu/~poyaoh/">Po-Yao Huang</a>,
              <a href="https://lyttonhao.github.io/">Yanghao Li</a>,
              <a href="https://haoqifan.github.io/">Haoqi Fan</a>,
              <a href="https://howardhsu.github.io/">Hu Xu</a>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <a href="https://cihangxie.github.io/">Cihang Xie</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://feichtenhofer.github.io/">Christoph Feichtenhofer</a>
              <br>
              <em>ICCV </em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2304.03283">arXiv</a>  /
              <a href="https://weichen582.github.io/diffmae.html">project page</a> /
              <a href="https://www.marktechpost.com/2023/04/11/a-new-ai-research-integrates-masking-into-diffusion-models-to-develop-diffusion-masked-autoencoders-diffmae-a-self-supervised-framework-designed-for-recognizing-and-generating-images-and-videos/">Marktechpost</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:40px;padding-left:0px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='smaug_image'><img style="width: 150%; height: auto;" src='images_new/smaug.png'></div>
              </div>
            </td>

            <td style="padding:40px;padding-top:30px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.11446">
                <papertitle> SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-Training </papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=0WFC2w0AAAAJ">Yuanze Lin</a>,
              <strong>Chen Wei</strong>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://cihangxie.github.io/">Cihang Xie</a>
              <br>
              <em>ICCV </em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2211.11446">arXiv</a>
              <br>
            </td>
          </tr>

          <tr onmouseout="hiera_stop()" onmouseover="hiera_start()" bgcolor="#ffffd0">
            <td style="padding:40px;padding-left:30px;padding-top:0px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hiera_image'><img style="width: 110%; height: auto;" src='images_new/hiera_before.png'></div>
                <img style="width: 110%; height: auto;" src='images_new/hiera_after.png'>
              </div>
              <script type="text/javascript">
                function hiera_start() {
                  document.getElementById('hiera_image').style.opacity = "1";
                }

                function hiera_stop() {
                  document.getElementById('hiera_image').style.opacity = "0";
                }
                hiera_stop()
              </script>
            </td>

            <td style="padding:40px;padding-top:50px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.11709">
                <papertitle> Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles </papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=4LWx24UAAAAJ">Chaitanya Ryali</a>*,
              <a href="https://scholar.google.com/citations?user=aMpbemkAAAAJ">Yuan-Ting Hu</a>*,
              <a href="https://dbolya.github.io/">Daniel Bolya</a>*,
              <strong>Chen Wei</strong>,
              <a href="https://haoqifan.github.io/">Haoqi Fan</a>,
              <a href="http://www.cs.cmu.edu/~poyaoh/">Po-Yao Huang</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=Qwm6ZOYAAAAJ">Vaibhav Aggarwal</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=42v1i_YAAAAJ">Arkabandhu Chowdhury</a>,
              <a href="https://omidpoursaeed.github.io/">Omid Poursaeed</a>,
              <a href="https://faculty.cc.gatech.edu/~judy/">Judy Hoffman</a>,
              <a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a>,
              <a href="https://lyttonhao.github.io/">Yanghao Li</a>*,
              <a href="https://feichtenhofer.github.io/">Christoph Feichtenhofer</a>*
              <br>
              <em>ICML </em>, 2023 <strong>Oral</strong>
              <br>
              <a href="https://arxiv.org/abs/2306.00989/">arXiv</a>  /
              <a href="https://github.com/facebookresearch/hiera">code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:40px;padding-left:20px;padding-bottom:0px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dmae_image'><img style="width: 130%; height: auto;" src='images_new/dmae.png'></div>
              </div>
            </td>

            <td style="padding:40px;padding-top:10px;padding-bottom:0px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2208.12256">
                <papertitle> Masked Autoencoders Enable Efficient Knowledge Distillers </papertitle>
              </a>
              <br>
              <a>Yutong Bai</a>,
              <a href="https://zeyuwang.netlify.app/">Zeyu Wang</a>,
              <a href="https://lambert-x.github.io/">Junfei Xiao</a>,
              <strong>Chen Wei</strong>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://yuyinzhou.github.io/">Yuyin Zhou</a>,
              <a href="https://cihangxie.github.io/">Cihang Xie</a>
              <br>
              <em>CVPR </em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2208.12256">arXiv</a>  /
              <a href="https://github.com/UCSC-VLAA/DMAE">code</a>
              <br>
            </td>
          </tr>

          <tr onmouseout="cp2_stop()" onmouseover="cp2_start()">
            <td style="padding:40px;padding-left:30px;padding-top:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cp2_image'><img style="width: 120%; height: auto;" src='images_new/cp2_before.png'></div>
                <img style="width: 120%; height: auto;" src='images_new/cp2_after.png'>
              </div>
              <script type="text/javascript">
                function cp2_start() {
                  document.getElementById('cp2_image').style.opacity = "1";
                }

                function cp2_stop() {
                  document.getElementById('cp2_image').style.opacity = "0";
                }
                cp2_stop()
              </script>
            </td>

            <td style="padding:40px;padding-top:40px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.11709">
                <papertitle> CP2: Copy-Paste Contrastive Pretraining for Semantic Segmentation </papertitle>
              </a>
              <br>
              <a>Feng Wang</a>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <strong>Chen Wei</strong>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://shenwei1231.github.io/">Wei Shen</a>
              <br>
              <em>ECCV </em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2203.11709">arXiv</a>  /
              <a href="https://github.com/wangf3014/CP2">code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:40px;padding-left:40px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='li_image'><img style="width: 120%; height: auto;" src='images_new/eccv2023li.png'></div>
              </div>
            </td>

            <td style="padding:40px;padding-top:50px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2205.01721">
                <papertitle> In Defense of Image Pre-Training for Spatiotemporal Recognition</papertitle>
              </a>
              <br>
              <a href="https://xhl-video.github.io/xianhangli/">Xianhang Li</a>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <strong>Chen Wei</strong>,
              <a href="https://meijieru.com/">Jieru Mei</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://yuyinzhou.github.io/">Yuyin Zhou</a>,
              <a href="https://cihangxie.github.io/">Cihang Xie</a>
              <br>
              <em>ECCV </em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2205.01721">arXiv</a> /
              <a href="https://github.com/UCSC-VLAA/Image-Pretraining-for-Video">code</a>
              <br>
            </td>
          </tr>

          <tr onmouseout="maskfeat_stop()" onmouseover="maskfeat_start()" bgcolor="#ffffd0">
            <td style="padding:40px;padding-top:0px;padding-left:30px;width:30%;vertical-align:middle">
              <br></br>
              <div class="one">
                <div class="two" id='maskfeat_image'><img style="width: 120%; height: auto;" src='images_new/maskfeat_after.png'></div>
                <img style="width: 120%; height: auto;" src='images_new/maskfeat_before.png'>
              </div>
              <script type="text/javascript">
                function maskfeat_start() {
                  document.getElementById('maskfeat_image').style.opacity = "1";
                }

                function maskfeat_stop() {
                  document.getElementById('maskfeat_image').style.opacity = "0";
                }
                maskfeat_stop()
              </script>
            </td>
            <td style="padding:40px;padding-top:40px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2112.09133.pdf">
                <papertitle> Masked Feature Prediction for Self-Supervised Visual Pre-Training </papertitle>
              </a>
              <br>
              <strong>Chen Wei*</strong>,
              <a href="https://haoqifan.github.io/">Haoqi Fan</a>,
              <a href="https://vcl.ucsd.edu/~sxie/">Saining Xie</a>,
              <a href="https://chaoyuan.org/">Chao-Yuan Wu</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://feichtenhofer.github.io/">Christoph Feichtenhofer*</a>
              <br>
              <em>CVPR </em>, 2022
              <br>
              <a href="https://www.paperdigest.org/2023/04/most-influential-cvpr-papers-2023-04/"><strong>Most Influential CVPR Papers (2023-04)</strong></a>
              <br>
              <a href="https://arxiv.org/pdf/2112.09133.pdf">arXiv</a>  /
              <a href="https://github.com/facebookresearch/SlowFast">code at pySlowFast</a>
              <br>
            </td>
          </tr>

          <tr onmouseout="ibot_stop()" onmouseover="ibot_start()" bgcolor="#ffffd0">
            <td style="padding:40px;padding-left:30px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ibot_image'><img style="width: 120%; height: auto;" src='images_new/ibot_after.png'></div>
                <img style="width: 120%; height: auto;" src='images_new/ibot_before.png'>
              </div>
              <script type="text/javascript">
                function ibot_start() {
                  document.getElementById('ibot_image').style.opacity = "1";
                }

                function ibot_stop() {
                  document.getElementById('ibot_image').style.opacity = "0";
                }
                ibot_stop()
              </script>
            </td>
            <td style="padding:40px;padding-top:80px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2111.07832.pdf">
                <papertitle> iBOT: Image BERT Pre-Training with Online Tokenizer </papertitle>
              </a>
              <br>
              <a href="https://shallowtoil.github.io/">Jinghao Zhou</a>,
              <strong>Chen Wei</strong>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <a href="https://shenwei1231.github.io/">Wei Shen</a>,
              <a href="https://cihangxie.github.io/">Cihang Xie</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="http://www.taokong.org/">Tao Kong</a>
              <br>
              <em>ICLR </em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2111.07832.pdf">arXiv</a>  /
              <a href="https://github.com/bytedance/ibot">code</a> /
              <a href="https://medium.com/syncedreview/meet-ibot-a-masked-image-modelling-framework-that-enables-bert-like-pretraining-for-vision-da01002115e7">press</a>
              <br>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="crest_stop()" onmouseover="crest_start()" bgcolor="#ffffd0">
            <td style="padding:40px;padding-left:30px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='crest_image'><img style="width: 120%; height: auto;" src='images_new/crest_after.png'></div>
                <img style="width: 120%; height: auto;" src='images_new/crest_before.png'>
              </div>
              <script type="text/javascript">
                function crest_start() {
                  document.getElementById('crest_image').style.opacity = "1";
                }

                function crest_stop() {
                  document.getElementById('crest_image').style.opacity = "0";
                }
                crest_stop()
              </script>
            </td>
            <td style="padding:40px;padding-top:60px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2102.09559.pdf">
                <papertitle> CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning </papertitle>
              </a>
              <br>
              <strong>Chen Wei</strong>,
              <a href="https://sites.google.com/site/kihyuksml/">Kihyuk Sohn</a>,
              <a href="https://scholar.google.com/citations?user=Vu3vH2sAAAAJ&hl=en">Clayton Mellina</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="http://users.umiacs.umd.edu/~fyang/">Fan Yang</a>
              <br>
              <em>CVPR </em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2102.09559.pdf">arXiv</a>  /
              <a href="https://github.com/google-research/crest">code</a> /
              <a href="files/CReST_poster.pdf">poster</a> /
              <a href="https://www.youtube.com/watch?v=cbXRfYBIt0w">video</a>
              <br>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="co2_stop()" onmouseover="co2_start()">
            <td style="padding:40px;padding-left:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='co2_image'><img style="width: 130%; height: auto;" src='images_new/co2_after.png'></div>
                <img style="width: 130%; height: auto;" src='images_new/co2_before.png'>
              </div>
              <script type="text/javascript">
                function co2_start() {
                  document.getElementById('co2_image').style.opacity = "1";
                }

                function co2_stop() {
                  document.getElementById('co2_image').style.opacity = "0";
                }
                co2_stop()
              </script>
            </td>
            <td style="padding:40px;padding-top:65px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.02217">
                <papertitle> CO2: Consistent Contrast for Unsupervised Visual Representation Learning</papertitle>
              </a>
              <br>
              <strong>Chen Wei</strong>,
              <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
              <a href="https://shenwei1231.github.io/">Wei Shen</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>
              <br>
              <em>ICLR </em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2010.02217">arXiv</a> /
              <a href="https://openreview.net/forum?id=U4XLJhqwNF1">Open Review</a> /
              <a href="https://iclr.cc/virtual/2021/poster/3354">video</a>
              <br>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="puzzle_stop()" onmouseover="puzzle_start()">
            <td style="padding:40px;padding-left:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='puzzle_image'><img style="width: 130%; height: auto;" src='images_new/puzzle_after.png'></div>
                <img style="width: 130%; height: auto;" src='images_new/puzzle_before.png'>
              </div>
              <script type="text/javascript">
                function puzzle_start() {
                  document.getElementById('puzzle_image').style.opacity = "1";
                }

                function puzzle_stop() {
                  document.getElementById('puzzle_image').style.opacity = "0";
                }
                puzzle_stop()
              </script>
            </td>
            <td style="padding:40px;;padding-top:70px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1812.00329">
                <papertitle> Iterative Reorganization with Weak Spatial Constraints: </br> Solving Arbitrary Jigsaw Puzzles for Unsupervised Representation Learning</papertitle>
              </a>
              <br>
              <strong>Chen Wei</strong>,
              <a href="http://lingxixie.com/">Lingxi Xie</a>,
              <a href="https://tonghelen.github.io/">Xutong Ren</a>,
              <a href="http://yingdaxia.github.io/">Yingda Xia</a>,
              <a href="https://scholar.google.com/citations?user=V-AVamQAAAAJ&hl">Chi Su</a>,
              <a href="http://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>,
              <a href="http://www.cs.utsa.edu/~qitian/">Qi Tian</a>,
              <a href="http://cs.jhu.edu/~ayuille/">Alan Yuille</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://arxiv.org/abs/1812.00329">arXiv</a> /
              <a href="https://github.com/weichen582/Unsupervised-Visual-Recognition-by-Solving-Arbitrary-Puzzles">code</a>
              <br>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="retinex_stop()" onmouseover="retinex_start()">
            <td style="padding:40px;padding-left:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='retinex_image'><img style="width: 130%; height: auto;" src='images_new/retinex_after.png'></div>
                <img style="width: 130%; height: auto;" src='images_new/retinex_before.png'>
              </div>
              <script type="text/javascript">
                function retinex_start() {
                  document.getElementById('retinex_image').style.opacity = "1";
                }

                function retinex_stop() {
                  document.getElementById('retinex_image').style.opacity = "0";
                }
                retinex_stop()
              </script>
            </td>

            <td style="padding:40px;padding-top:105px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1808.04560">
                <papertitle> Deep Retinex Decomposition for Low-Light Enhancement </papertitle>
              </a>
              <br>
              <strong>Chen Wei*</strong>,
              <a href="https://daooshee.github.io/website/">Wenjing Wang</a>*,
              <a href="https://flyywh.github.io/index.html">Wenhan Yang</a>,
              <a href="http://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>
              <br>
              <em>BMVC</em>, 2018 <strong>Oral</strong>
              <br>
              <a href="https://scholar.google.com/citations?hl=en&vq=eng_computervisionpatternrecognition&view_op=list_hcore&venue=T_DfB2ikUbwJ.2022"><strong>Most Cited BMVC Papers Over the Last Five Years No.2</strong></a>
              </br>
              <a href="https://arxiv.org/abs/1808.04560">arXiv</a> /
              <a href="https://github.com/weichen582/RetinexNet">code</a> /
              <a href="https://daooshee.github.io/BMVC2018website/">project page & dataset</a>
              <br>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="glad_stop()" onmouseover="glad_start()">
            <td style="padding:40px;padding-left:20px;padding-top:20px;width:30%;vertical-align:middle">
              <br></br>
              <div class="one">
                <div class="two" id='glad_image'><img style="width: 130%; height: auto;" src='images_new/glad_after.png'></div>
                <img style="width: 130%; height: auto;" src='images_new/glad_before.png'>
              </div>
              <script type="text/javascript">
                function glad_start() {
                  document.getElementById('glad_image').style.opacity = "1";
                }

                function glad_stop() {
                  document.getElementById('glad_image').style.opacity = "0";
                }
                glad_stop()
              </script>
            </td>
    
            <td style="padding:40px;width:70%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8373911">
                <papertitle> GLADNet: Low-Light Enhancement Network with Global Awareness</papertitle>
              </a>
              <br>
              <a href="https://daooshee.github.io/website/">Wenjing Wang</a>*,
              <strong>Chen Wei*</strong>,
              <a href="https://flyywh.github.io/index.html">Wenhan Yang</a>,
              <a href="http://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>
              <br>
              <em>FG Workshop</em>, 2018
              <br>
              <a href="http://39.96.165.147/Pub%20Files/2018/wwj_fg2018.pdf">PDF</a> /
              <a href="https://github.com/weichen582/GLADNet">code</a> /
              <a href="https://daooshee.github.io/fgworkshop18Gladnet/">project page</a>
              <br>
              <p></p>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
              <td width="100%" valign="middle">
                  <heading>Experience</heading>
                  <!-- <br /> -->
              <ul>
                <li>Student Researcher, Google Brain, Summer 2023</li>
              </ul>
              <ul>
                <li>Research Intern, Facebook AI Research (Meta AI), Summer 2022</li>
              </ul>
              <ul>
                <li>Research Intern, Facebook AI Research, Summer 2021</li>
              </ul>
              <ul>
                <li>Research Intern, Google Cloud AI, Summer 2020</li>
              </ul>
              <ul>
                <li>Research Intern, Johns Hopkins University, Summer 2018</li>
              </ul>
              <ul>
                <li>Engineering Practium Intern, Google, Summer 2017</li>
              </ul>
              <ul>
                <li>Research Intern, <a href="http://www.icst.pku.edu.cn/struct/">STRUCT</a> Lab, Peking University, 2017 - 2019</li>
              </ul>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                  Last update: July. 2023 &nbsp&nbsp&nbsp&nbsp <a href="https://jonbarron.info/">Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
